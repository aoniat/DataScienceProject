# DataScienceProject by Erick,Dhruv,Santiago and Aonia
BST260-Wine
Overview and Motivation: Provide an overview of the project goals and the motivation for it. Consider that this will be read by people who did not see your project proposal.
Wine making is both a science and an art. Chemical characteristics affect the taste and can make a wine good or bad. However, there is a poetic side to wine: each wine can have notes and fragrances that can remind us of wood, fruits, raspberry, licorice… and this is where individual taste and a specific mood comes into play.Our project aimed to explore both aspects: the chemical one by building a model to predict wine quality from chemical properties like acidity, phenols, etc.; and the poetic one, by creating a recommendation system for any wine enthusiast to be able to search for wines with certain taste or fragrance notes.

Related Work: Anything that inspired you, such as a paper, a web site, or something we discussed in class.
We wanted to explore predictive models, as well as natural language processing. We were familiar with apps like Vivino that can recommend wine, and wanted to do a variation on that, which also takes into consideration the chemical composition that makes a good wine.

Initial Questions: What questions are you trying to answer? How did these questions evolve over the course of the project? What new questions did you consider in the course of your analysis?
What makes a good wine? This question drove the bulk of our analyses, eventually leading us to utilize both ordinal logistic regressions and random forests for predictive analysis of the wine qualities. Important facets of a wine were determined through traditional regression and machine learning techniques, and were thus incorporated into our final results for what makes a wine great. This question remained constant throughout our various analyses.

For the wine recommender idea, our main goal was to create a Shiny app where a user could specify a price range, and some keywords for the wine description. Initially we thought of allowing the user to specify a score, but then decided that we would just display the wines with the highest scores: everything else being equal, who wouldn’t a priori prefer a wine with a higher score? There were two changes that we decided during the course of the project: first we had planned to display some words from the description according to their frequency, but ended up doing something else instead. We thought it would be interesting to show the relative frequency of wines meeting the user criteria by country, so we added this as a visualization.

Data: Source, scraping method, cleanup, etc.
We found the data set in a Kaggle repository. Wehad to download it and clean it. The cleanup consisted of removing rows with missing values for variables we wanted to use. The remaining data set after cleaning and wrangling the data was still large (>7k) giving us power to both determine what makes a good wine and recommend the wine data. To reduce the size of the recommendation data set, we also decided to keep only wines with a score above a certain number (88), since we’ll only show the top-scoring wines. Similarly, data cleaning involved creating new categorical outcomes for wine quality based on already available data sets, with distinct cutoffs for each “bin” of wine quality (low, average, high).

Exploratory Analysis: What visualizations did you use to look at your data in different ways? What are the different statistical methods you considered? Justify the decisions you made, and show any major changes to your ideas. How did you reach these conclusions?
Exploratory analysis for the predictive modeling began with linear regressions, but when robustness checks demonstrated the failure of certain assumptions, we moved to ordinal regression and random forests. We used predicted probability charts and plots, regression and analysis outputs, and density plots among other visualizations to assess the data and different ways and approach it from different angles. These are explained in a lot of detail in the R-markdown files as well.

For the wine recommender, we did data processing and Natural Language Processing (NLP). The main thing was checking the data missingness to see if excluding wines that had any of our fields of interest missing (score, price, description, wine name and country) would result in too many total exclusions. We did initially consider adding a filter by region, but we noticed there were too many regions to include in the filter, so we ended up not using it or displaying that information, except for what is available in the wine name.We also did natural language processing and one of the things that we need to check in that case is if the word we search is used in a negative way. In our case however, it was very unlikely that a keyword would be mentioned if it had to be taken in a negative way. We checked a few results and saw that there were almost no instances of negative results applied to important words."

Final Analysis: What did you learn about the data? How did you answer the questions? How can you justify your answers?
We were curious to learn about hwat makes a good wine, and were able to learn about different models, their assumptions, as well as their strengths and weaknesses in the process. Decision trees for example are often used as decision support, where each node is a test (e.g. is alcohol proof below or abve 10%), and each branch represents the outcocme of this test. To construct a random forests we used 500 trees per forest, with trees created by randomly choose three features of the wine (e.g. pH, sugar levels and alcohol proof) . Each tree in the forest will classify the wine as good or bad quality, and the most common predictiton of the trees acriss the forest is the classificatiton which will be assigned.The error rate (called out of bag error), is estimated by testing our tree decisions on the samples which were not included to create the decision trees.We were able to correctly classify good red wine with 17% error rate and good white wine with a 9% error rate. This means we are correctly classifying a good white wine as good white wine more than 90% of the time in our testing set. This is far better predictive ability than the original simple linear regression which explained only 27% of variability for white wine and 35% for red wine.

However overall, we found similar results for both the ordinal logistic regression and random forests, with alcohol, total sulfur dioxide, and chlorides (among a few other facets) taking precedence over the other covariates included in our data set. Our robustness checks and the satisfaction of assumptions in our analyses justify the answers obtained from the models.

It was hence very interersting to read into the relationship between quantittative findings, and what these meant that one should watch out for when smelling and tasting wines, for example that sulfur dioxide gives a citrus or smoky taste, and those are linked to better wine quality. Linking the chemical compositions to our recommendation system was also fun as the researcch regarding smell and chemical composition allowed us to make recommendations on the basis of what makes a good wine as well as eprsonal preferencec.

In addition, we learned that our recommendation system works. By playing with it, we found interesting things, for example: a full 8% of Canadian wines are described as “aromatic”. This is almost double the percentage of any of the other countries in our data set. Also, a larger proportion of french wines (15%) tend to be “dry”.
